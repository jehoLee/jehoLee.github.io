---
title: "Least Square Problem (최소제곱 문제)"
use_math: true
---

통계적 모델링의 표준적인 기법인 **Least square** (최소제곱법)은 주어진 데이터 포인트들에 가장 가까운 직선 또는 곡선을 구하는 방법으로 Regression analysis (회귀 분석)에서 사용된다.

측정된 데이터들을 통해 예측 모델을 만들어내는 것은 주위 많은 분야에서 적용되고 있으며, 최소제곱법은 그 기본적인 방법이라고 볼 수 있다. 

**Least square problem** (최소제곱 문제)는 일반적으로 Overdetermined system, 즉 방정식이 미지수보다 많은 연립 방정식을 푸는 것을 말한다. 이런 방정식은 대게 모순으로 해가 존재하지 않는다. 다시 말해 m x n 행렬 A에 의한 선형 연립방정식 Ax = b 가 주어지고 m > n (overdetermined) 이라면, 방정식의 solution인 n 차원의 벡터 x가 존재하기를 기대하기 어렵다. 따라서, Ax - b 가 0에 가까운 벡터 x를 찾아야한다.

선형 연립방정식 Ax = b이 주어지고, A는 m x n (m > n) 행렬이라면,
$$
r(x) = b - Ax
$$
의 크기를 구하여 이를 최소화하는 solution을 구할 수 있다.
$$
Ax = b
$$
의 최소제곱 해를 구하기 위해서는 다음의 방정식을 풀어야 한다.


$$
A^TAx=A^Tb
$$


위 방정식으로 부터 구한 최소제곱 해 
$$
\hat{x}
$$
를 계수로 갖는 직선의 방정식을 **Least square fit** 이라고 한다.

수집된 데이터들로 특정 함수를 도출해내어 미래의 데이터를 예측하려는 시도는 고차 함수로 모델링하여 해결할 수도 있겠지만, 만약 데이터가 특정 직선에서 매우 적은 오차만큼 떨어져 있는 형태 (거의 직선 상에 존재)라면 고차 함수 모델링은 전혀 맞지 않는 예측을 할 것이다.

따라서 이 경우 Least square fit이 적절하며, 직선의 방정식 뿐 아니라 곡선의 방정식으로도 모델링 할 수 있다.



MSE?